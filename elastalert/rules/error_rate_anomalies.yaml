version: '3.7'

services:
  # Elasticsearch - Use production settings
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=production-monitoring-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      # Add security if needed
      # - xpack.security.enabled=true
      # - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - monitoring-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"\\|\"status\":\"yellow\"'"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Logstash - Production configuration
  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.0
    container_name: logstash
    environment:
      - "LS_JAVA_OPTS=-Xms1g -Xmx1g"
      # Add security if needed
      # - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/templates:/etc/logstash/templates:ro
    ports:
      - 5044:5044
      - 9600:9600
      - 8080:8080
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--silent", "--fail", "localhost:9600/_node/stats"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Kibana - Production configuration
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      # Add security if needed
      # - ELASTICSEARCH_USERNAME=elastic
      # - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
    ports:
      - 5601:5601
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--silent", "--fail", "localhost:5601/api/status"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Filebeat - Configured for production log collection
  filebeat:
    image: docker.elastic.co/beats/filebeat:7.17.0
    container_name: filebeat
    user: root  # Required to access logs
    volumes:
      - ./filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker log access
      
      # Actual production logs - adjust paths to your environment
      - /opt/application/logs:/opt/production-logs:ro
      - /var/log/nginx:/var/log/nginx:ro
      - /var/log/api-services:/var/log/api-services:ro
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
      - logstash
    command: ["filebeat", "-e", "-strict.perms=false"]
    restart: unless-stopped
    environment:
      - ELASTIC_HOSTS=elasticsearch:9200
      # Add security if needed
      # - ELASTIC_USER=elastic
      # - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}

  # Elastalert for alerting - connected to real production data
  elastalert:
    image: jertel/elastalert2:2.6.0
    container_name: elastalert
    volumes:
      - ./elastalert/config/config.yaml:/opt/elastalert/config.yaml
      - ./elastalert/rules:/opt/elastalert/rules
      - ./elastalert/logs:/opt/elastalert/logs
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      # Add security if needed
      # - ELASTICSEARCH_USER=elastic
      # - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      # Add SMTP configuration for email alerts
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_AUTH=${SMTP_AUTH}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - SMTP_FROM=${SMTP_FROM}

  # Jaeger for distributed tracing - connected to production services
  jaeger:
    image: jaegertracing/all-in-one:1.35
    container_name: jaeger
    ports:
      - 16686:16686  # Web UI
      - 6831:6831/udp  # Jaeger thrift compact
      - 14268:14268  # Jaeger HTTP collector
      - 4317:4317  # OTLP gRPC
      - 4318:4318  # OTLP HTTP
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_TAGS_AS_FIELDS_ALL=true
      # Add security if needed  
      # - ES_USERNAME=elastic
      # - ES_PASSWORD=${ELASTIC_PASSWORD}
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Python Anomaly Detection Service - Production version
  anomaly-detection:
    build:
      context: ./anomaly-detection
      dockerfile: Dockerfile
    container_name: anomaly-detection
    volumes:
      - ./anomaly-detection:/app
      # Add logs volume if needed
      - ./logs:/app/logs
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
    restart: unless-stopped
    environment:
      - ES_HOST=elasticsearch
      - ES_PORT=9200
      # Add security if needed
      # - ES_USER=elastic
      # - ES_PASSWORD=${ELASTIC_PASSWORD}
      
      # Configuration for production
      - ANALYSIS_INTERVAL=300
      - HISTORICAL_WINDOW=24
      - MAX_SAMPLES=100000
      - ANOMALY_THRESHOLD=0.02
      - MIN_DATA_POINTS=10
      
      # Production alert settings
      - ALERT_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - PAGERDUTY_API_KEY=${PAGERDUTY_API_KEY}
      - ALERT_EMAIL=${ALERT_EMAIL}
      
      # Service filtering (optional)
      - INCLUDED_SERVICES=user-service,product-service,payment-service,notification-service
      # - EXCLUDED_SERVICES=test-service,qa-service
      
      # Response time threshold in ms
      - RESPONSE_TIME_THRESHOLD=1000
      # Error rate threshold (0.1 = 10%)
      - ERROR_RATE_THRESHOLD=0.1
      
      # Index pattern for your actual API logs
      - API_LOGS_INDEX=api-logs-*

  # Grafana for additional dashboards (optional)
  grafana:
    image: grafana/grafana:9.3.6
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - monitoring-network
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Prometheus for metrics collection (optional)
  prometheus:
    image: prom/prometheus:v2.42.0
    container_name: prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - monitoring-network
    restart: unless-stopped

# Include your actual API services here for direct monitoring

  # Example API service 1 (replace with your real services)
  user-service:
    image: ${USER_SERVICE_IMAGE}
    container_name: user-service
    ports:
      - "8001:8000"
    environment:
      - SERVICE_NAME=user-service
      - ENVIRONMENT=production
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=4317
      - LOG_LEVEL=INFO
      # Add your actual service environment variables
    volumes:
      - ./logs/user-service:/app/logs
    networks:
      - monitoring-network
    restart: unless-stopped
    depends_on:
      - elasticsearch
      - jaeger

  # Example API service 2 (replace with your real services)
  product-service:
    image: ${PRODUCT_SERVICE_IMAGE}
    container_name: product-service
    ports:
      - "8002:8000"
    environment:
      - SERVICE_NAME=product-service
      - ENVIRONMENT=production
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=4317
      - LOG_LEVEL=INFO
      # Add your actual service environment variables
    volumes:
      - ./logs/product-service:/app/logs
    networks:
      - monitoring-network
    restart: unless-stopped
    depends_on:
      - elasticsearch
      - jaeger

  # Example API service 3 (replace with your real services)
  payment-service:
    image: ${PAYMENT_SERVICE_IMAGE}
    container_name: payment-service
    ports:
      - "8003:8000"
    environment:
      - SERVICE_NAME=payment-service
      - ENVIRONMENT=production
      - JAEGER_HOST=jaeger
      - JAEGER_PORT=4317
      - LOG_LEVEL=INFO
      # Add your actual service environment variables
    volumes:
      - ./logs/payment-service:/app/logs
    networks:
      - monitoring-network
    restart: unless-stopped
    depends_on:
      - elasticsearch
      - jaeger

volumes:
  elasticsearch-data:
  prometheus-data:
  grafana-data:

networks:
  monitoring-network:
    driver: bridge